Name: Rebecca Lassman
How to compile:
How to run:
Bugs/limitations: The indexes for the attributes used to test for equality are stored as final ints in LookupNYPDData and will have to be changed if the indexes for these attributes are different for other files (I.e., if race is stored in column 82 rather than 81 as it is in 2011.csv, the RACE variable will have to be changed to 82). Also, my program only checks if data is missing using 2011.csv’s format, which has 12311900 if date of birth is missing and ‘Z’ or ‘U’ if race or sex is missing/unknown. If other files format missing data differently, my program would need to be adjusted.
Discussion:
1. I determine uniqueness by comparing a String containing the race, sex, date of birth, height (feet and inches), weight, hair color, eye color, and build of the suspect. If any of these attributes are missing (I.e., the birthday is 12/31/1900) a static integer is added to the String and then incremented to prevent suspects with missing data from being considered equal to another suspect, since it is less likely that two rows are the same person if data is missing. Although it is possible that two different people could share all these characteristics, it is most likely the same person. Also, none of the other data provided in a row is helpful for determining uniqueness, since the location of the stop could be different for the same person since people travel around, and the only other data is related to the specific incident.  
2. When run on the entire 2011 SQF data set, all pairs took 112606834 milliseconds, linear hash took 8224 ms, double hash took 7436 ms, quick sort took 35298 ms, and java’s built-in sort took 14897 ms. Also, please note that the complexity graph only includes all pairs’ run times for 0, 50000, and 100000 rows because it takes too long to run to record more data and it would mess up the scale for the other methods. 
3. The double hash deduplication method was the most efficient, although it is important to note that the exact runtime differs with each run because the number of probes differs due to the keys having different hash codes with each run, since the memory address changes. However, on average it is a bit faster than linear hashing and much faster than the other three methods. This is because the runtime of inserting into a hash table is expected to be O(1) for each element (O(n) total), while the sorts are O(nlogn), and all pairs is O(n^2). Both the built-in sort (merge sort) and quick sort have a worst-case runtime of O(nlogn). However, if quick sort chooses a pivot that is smaller or larger than most of the other elements, the runtime increases, with a worst-case of O(n^2) if the worst pivot is chosen every time. While this is highly unlikely, the massive size of this data set increases the number of recursive calls, and thus increases the likelihood that a bad pivot will be chosen at some point. Even choosing a bad pivot a few times early on with such a large data set will significantly increase the runtime. Additionally, java’s built-in sort is a merge sort optimized to be as efficient as possible, while my quick sort has no optimizations (such as safeguarding against bad pivots). 
4. The average number of hashes decreased slightly with the double hash, but the max number of hashes decreased more dramatically. With linear hashing, the average number of probes is around 2.39 and the max number of probes is about 30-35. For double hashing, the average is around 2.28 and the max is around 15. Double hashing is more efficient because it reduces secondary collisions caused by clustering, which leads to fewer long sequences of probing. Thus, the average only changes slightly because there are still the same number of primary collisions, but the max number is reduced more significantly because it takes less probes to find the next available spot. Since there are fewer probes with double hashing, it is generally faster than linear hashing, although because the number of probes is different with each run, there are occasionally cases where linear happens to be slightly faster.  
